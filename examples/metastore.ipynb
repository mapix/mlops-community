{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metastore Demo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metastore sdk 安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metastore安装\n",
    "# pip install --upgrade \"dp-metadata-sdk\" -i https://repo.mlops.dp.tech/repository/pypi-group/simple\n",
    "import dp.metadata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成假数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20+0 records in\n",
      "20+0 records out\n",
      "20971520 bytes (21 MB, 20 MiB) copied, 0.00784302 s, 2.7 GB/s\n",
      "metastore.ipynb  mocked.dataset  tracking.ipynb\n"
     ]
    }
   ],
   "source": [
    "\n",
    "! dd if=/dev/zero of=mocked.dataset bs=1M count=20\n",
    "! ls"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 环境变量配置"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metastore本质上是一个元数据管理平台，并没有数据存储的功能，因此需要与提供存储功能的应用一起使用，可以简单将其理解成metastore只负责存储数据的指针，而指针具体指向了什么位置，怎么调用需要另外的模块来一起协作实现。目前推荐的做法是利用dflow的对象存储功能，将数据存储为artifacts，再利用其uri（对应artifact.key）对数据进行使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bohrium 环境配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据上传下载不需要配置 bohrium project id\n",
    "bohrium_username = 'yaosk@dp.tech'\n",
    "bohrium_passwd = ''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dflow环境配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dflow.plugins.bohrium import TiefblueClient\n",
    "from dflow.plugins import bohrium\n",
    "from dflow import config, s3_config\n",
    "import json\n",
    "\n",
    "# 详情可以参考dflow尝鲜群群公告\n",
    "# dflow相关配置\n",
    "config[\"host\"] = \"https://workflows.deepmodeling.com\"\n",
    "config[\"k8s_api_server\"] = \"https://workflows.deepmodeling.com\"\n",
    "# dflow token请到dflow尝鲜群-群公告里查找，注意token要与host匹配\n",
    "config[\"token\"] = \"...\"\n",
    "\n",
    "# bohrium账号密码\n",
    "bohrium.config[\"username\"] = bohrium_username\n",
    "bohrium.config[\"password\"] = bohrium_passwd\n",
    "\n",
    "# 存储功能配置（s3统一存储）\n",
    "s3_config[\"repo_key\"] = \"oss-bohrium\"\n",
    "s3_config[\"storage_client\"] = TiefblueClient()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metastore 环境变量配置"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主要的两个变量参数endpoint、token。官方提供的endpoint为(https://datahub-gms.dp.tech/), token可以在datahub的前端界面（https://datahub.dp.tech/ ）通过右上角的setting拿到。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dp.metadata.context import MetadataContext\n",
    "\n",
    "endpoint = 'https://datahub-gms.dp.tech'\n",
    "token = ''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uri: 指向真实的数据存储地址，形如s3://xxxx，只要解析s3协议就能在全网找到该数据集，数据集和uri一一对应  \n",
    "urn：metastore 统一名称表示符，用于传递数据集，具有一定的可读性。一个urn指向唯一一份数据集，但多个urn可指向同一份数据集"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据上传下载\n",
    "\n",
    "结合上述说明，数据的上传分为两步，第一步是向对象存储中传输真实的数据，第二步是将数据的uri、描述说明等元信息注册到datahub中。在这里我们有两种办法，第一个是直接调用原生的dflow上传接口，然后将artifact.key作为dataset的uri注册到datahub中，第二种方法是在context中声明一个storage client，只要在参数中指定bohrium邮箱和密码即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "方法1：使用 dflow 内置的 upload_artifact 上传并注册到 metastore，下载时使用 dflow 的 download_artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset urn: urn:li:dataset:(urn:li:dataPlatform:MLOps demo,default.mocked_dataset1,CORP)\n",
      "dataset1\n",
      "this is a dataset\n",
      "11874/0/store/11874/upload/37aaa4b7-fc84-446b-93a3-d4bbf02f4571/tmpixens0qr.tgz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./download_dflow/mocked.dataset']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第一种方式\n",
    "from dflow import upload_artifact, download_artifact\n",
    "from dp.metadata import Dataset\n",
    "import os\n",
    "import dflow\n",
    "\n",
    "# -------------------------------上传数据-------------------------------\n",
    "# 使用 dflow 上传数据获得 artifact\n",
    "artifact = upload_artifact('mocked.dataset')\n",
    "\n",
    "# 将 uri 注册到datahub中\n",
    "with MetadataContext(endpoint=endpoint, token=token) as context:\n",
    "    dataset_urn = Dataset.gen_urn(context, 'MLOps demo', 'mocked_dataset1', auto_suffix=False)\n",
    "    dataset = Dataset(urn=dataset_urn, description='this is a dataset', uri=artifact.key)\n",
    "    client = context.client\n",
    "    urn = client.create_dataset(dataset)\n",
    "    print(\"dataset urn:\", urn)\n",
    "\n",
    "# -------------------------------下载数据-------------------------------\n",
    "_dataset = client.get_dataset(urn)\n",
    "print('dataset1')\n",
    "print(_dataset.description)\n",
    "print(_dataset.uri)\n",
    "\n",
    "data_artifact = dflow.S3Artifact.from_dict({'key': _dataset.uri})\n",
    "dflow.download_artifact(\n",
    "    data_artifact,\n",
    "    path=str('./download_dflow'),\n",
    "    skip_exists=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "方法2：只使用 metadata 上传下载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 16:15:51.447 INFO    dp.metadata.client.client: Uploading /mnt/vepfs/users/yaosk/code/mlops-hello-world/examples/mocked.dataset\n"
     ]
    }
   ],
   "source": [
    "# 第二种方式\n",
    "from dp.metadata.utils.storage import TiefblueStorageClient\n",
    "import uuid\n",
    "\n",
    "# -------------------------------上传数据-------------------------------\n",
    "# metasotre负责上传并注册数据\n",
    "with MetadataContext(endpoint=endpoint, token=token) as context:\n",
    "    context.storage_client = TiefblueStorageClient(username=bohrium_username, password=bohrium_passwd)\n",
    "    client = context.client\n",
    "    _uuid = uuid.uuid4().hex\n",
    "    uri = client.upload_artifact(_uuid, '', 'mocked.dataset')\n",
    "    dataset_urn = Dataset.gen_urn(context, 'MLOps demo', 'mocked_dataset2', auto_suffix=False)\n",
    "    dataset = Dataset(urn=dataset_urn, description='this is a dataset', uri=uri)\n",
    "    client = context.client\n",
    "    urn = client.create_dataset(dataset)\n",
    "\n",
    "# -------------------------------下载数据-------------------------------\n",
    "# MetadataContext传入的参数有两种写法，这一种和上面一种都可以\n",
    "with MetadataContext(endpoint=endpoint, token=token, storage_client=TiefblueStorageClient(username=bohrium_username, password=bohrium_passwd)) as context:\n",
    "    client = context.client\n",
    "    client.download_dataset(urn, './download_metastore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意\n",
    "方法1上传的数据可以用方法2下载，但是不建议这么用。两者上传的方式有细微区别，某些情况下可能报错。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dflow 中使用 metastore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将数据作为 op 的 parameters 使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pathlib import Path\n",
    "\n",
    "import dflow\n",
    "\n",
    "# 在没有 metastore 的时候，数据从本地上传后生成dflow.S3Artifact，再传入op中使用。\n",
    "artifact1 = upload_artifact('mocked.dataset')\n",
    "\n",
    "# 当使用 metastore 时，将 urn 转化为 Artifact 传入dflow中\n",
    "# 已经上传的数据的urn\n",
    "dataset_urn = 'urn:li:dataset:(urn:li:dataPlatform:MLOps demo,default.mocked_dataset2,CORP)'\n",
    "with MetadataContext(endpoint=endpoint, token=token, storage_client=TiefblueStorageClient(username=bohrium_username, password=bohrium_passwd)) as context:\n",
    "    client = context.client\n",
    "    # dataset 是数据集的根目录\n",
    "    dataset = client.get_dataset(dataset_urn)\n",
    "    artifact2 = dflow.S3Artifact(key=dataset.uri)\n",
    "    # 列出根目录下所有文件\n",
    "    subdataset_list = client.list_artifact(dataset.uri)\n",
    "    # 该数据集中只有一个文件，选取subdataset_list[0]作为key生成S3Artifact\n",
    "    artifact3 = dflow.S3Artifact(key=subdataset_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "artifact1 和 artifact3 可作为 Artifact(Path) 直接输入dflow的OP中, artifact2 可作为 Artifact(List[Path]) 传入OP中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在 op 中上传下载数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "方法同【数据上传下载】一节中的数据上传下载方法。  \n",
    "注意：**禁止使用 parameters 传递账号密码和token，存在泄密风险**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dflow中传入账号密码和token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "```\n",
    "# 需要加密的环境变量\n",
    "envs = {\n",
    "        \"DATAHUB_GMS_TOKEN\": \"...\",\n",
    "        \"DATAHUB_GMS_URL\": \"https://datahub-gms.dp.tech\",\n",
    "        \"bohrium_username\": \"xxxx\",\n",
    "        \"bohrium_passwd\": \"xxxx\",\n",
    "}\n",
    "\n",
    "# 使用dflow加密\n",
    "from dflow import Secret\n",
    "envs = {k: Secret(str(v)) for k, v in envs.items()}\n",
    "\n",
    "# 作为envs参数传入OP中\n",
    "step = Step(\n",
    "    'hello',\n",
    "    template=PythonOPTemplate(\n",
    "        xxxOP,\n",
    "        envs=envs,\n",
    "    ),\n",
    "    parameters={\n",
    "        ...\n",
    "    },\n",
    "    artifacts={\n",
    "        ...\n",
    "    },\n",
    "    executor = ...\n",
    ")\n",
    "\n",
    "\n",
    "@OP.function\n",
    "def Hello(filename: str) -> {'foo': Artifact(Path)}:\n",
    "    open(filename, \"w\").write(\"foo\")\n",
    "    # OP中使用os.environ读取加密的环境变量\n",
    "    # 注意：metastore 默认从环境变量\"DATAHUB_GMS_URL\"和\"DATAHUB_GMS_TOKEN\"读取endpoint和token，因此这里无需再传入\n",
    "    with MetadataContext(\n",
    "        storage_client=TiefblueStorageClient(username=os.environ[\"bohrium_username\"], password=os.environ[\"bohrium_passwd\"])) as context:\n",
    "        ....\n",
    "    return {'foo': Path(filename)}\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('bm_stack')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3d55901b6d0993a7fdd07891420d84cd0815204ece45c4d2384a6c034757fe3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
